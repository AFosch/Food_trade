{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create multliayer Food groups \n",
    "It is a copy of Multilayer food_groups.ipynb but that I am going to mess-up to tranform into a code that I can apply to make trajectories of a country across the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import networkx as nx\n",
    "import geopandas as gpd # pip installed\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Edge_overlap_w(data, direction, weight):\n",
    "    \"\"\"Calculate the weighted edge overlap for each 'origin_country_ISO' in a DataFrame.\n",
    "\n",
    "    In weighted multilayer networks the edge overlap is the sum of all the weights of all out-links in each node.  \n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): Input DataFrame containing at least the 'origin_country_ISO' and 'value' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with edge overlap calculated for each 'origin_country_ISO'.\n",
    "    The output DataFrame has one column named 'overlap' representing the calculated edge overlap weights.\n",
    "\n",
    "    Example:\n",
    "    >>> df_result = Edge_overlap_w(input_data)\n",
    "    \"\"\"\n",
    "\n",
    "    if direction == 'out':\n",
    "        country_group = 'origin_country_ISO'\n",
    "    else: \n",
    "        country_group = 'destin_country_ISO'\n",
    "\n",
    "\n",
    "    if weight==True:\n",
    "        overlap_w= data.groupby(['origin_country_ISO']).apply(lambda group : group.value.sum())\n",
    "    else:\n",
    "        overlap_w= data.groupby(['origin_country_ISO']).apply(lambda group : len(group))\n",
    "\n",
    "    overlap_w= pd.DataFrame(overlap_w.sort_values(ascending=False),columns=['o_i'])\n",
    "    return overlap_w\n",
    "\n",
    "def Node_strength(data, direction, group_class, weight = True):\n",
    "    \"\"\" Calculate the node relevance in each layer of the multilayer network. \n",
    "    In a weighted directed network the country strenght is the sum of the magnitude exported by that country in that layer.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): Input DataFrame containing trade data for a single year. The dataframe must contain \n",
    "    the columns: 'item', 'unit', 'origin_country_ISO', and 'value'.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with country strength for each combination of 'item' and 'unit', sorted from highest to lowest. \n",
    "    Columns include 'item', 'unit', 'origin_country_ISO', and the calculated 'value' for node strength.\n",
    "\n",
    "    Example:\n",
    "    >>> df_result = Node_strength_w(input_data)\n",
    "    \"\"\"\n",
    "    if direction == 'out':\n",
    "        country_group = 'origin_country_ISO'\n",
    "    else: \n",
    "        country_group = 'destin_country_ISO'\n",
    "\n",
    "    if (weight==True):\n",
    "        str_i_l = data.groupby([group_class,'unit']).apply(lambda group: group.loc[:,[country_group,'value']].\n",
    "                                                        pivot_table(index=country_group, aggfunc='sum').\n",
    "                                                        sort_values(by = 'value',ascending=False))\n",
    "        strength_i_l= str_i_l.reset_index(level=[group_class,'unit',country_group]).rename(columns={'value':'str_i_l'})\n",
    "\n",
    "    else:\n",
    "        data['dum_weight']= 1\n",
    "        str_i_l = data.groupby([group_class,'unit']).apply(lambda group: group.loc[:,[country_group,'value']].\n",
    "                                                        pivot_table(index=country_group, aggfunc=lambda x: len(x)).\n",
    "                                                        sort_values(by = 'value',ascending=False))\n",
    "        strength_i_l= str_i_l.reset_index(level=[group_class,'unit',country_group]).rename(columns={'value':'str_i_l'})\n",
    "\n",
    "    return strength_i_l\n",
    "    \n",
    "def Participation_coeff_old (data,overlap):\n",
    "\n",
    "    #Define elements for part_coeff\n",
    "    L = len(data[group_class].unique())\n",
    "\n",
    "    \n",
    "    s_i_l = Node_strength_w(data)\n",
    "\n",
    "    # Prepare data\n",
    "    data_for_Pc = pd.merge(s_i_l, overlap.loc[:,['country','overl']], left_on= 'origin_country_ISO',right_on='country', how='left')\n",
    "\n",
    "\n",
    "    # Contibution of each layer to total exports\n",
    "    data_for_Pc['sum_layers'] = (data_for_Pc['str_i_l']/data_for_Pc['overl'])**2\n",
    "    \n",
    "    sum_layers= data_for_Pc.groupby(['origin_country_ISO']).apply(lambda group: group.sum_layers.sum())\n",
    "\n",
    "    particip_coeff =  pd.DataFrame((L/(L-1))*(1- sum_layers),columns=['partic_coeff']).sort_values(by='partic_coeff',ascending=False)\n",
    "    return particip_coeff \n",
    "  \n",
    "def Participation_coeff (data, overlap, direction, group_class, weight):\n",
    "\n",
    "    if (weight == True):\n",
    "        w_f = '_w'\n",
    "        flag_overlap = 'overl'\n",
    "    else:\n",
    "        w_f = ''\n",
    "        flag_overlap = 'deg'\n",
    "\n",
    "    if direction == 'out':\n",
    "        country_group = 'origin_country_ISO'\n",
    "    else: \n",
    "        country_group = 'destin_country_ISO'\n",
    "    #Define elements for part_coeff\n",
    "    L = len(data[group_class].unique()) # Is this correct???\n",
    "    \n",
    "    s_i_l = Node_strength(data, direction, group_class,weight)\n",
    "\n",
    "    # Prepare data\n",
    "    #data_for_Pc = pd.merge(s_i_l, o_i, left_on= 'origin_country_ISO',right_index=True, how='left')\n",
    "    data_for_Pc = pd.merge(s_i_l, overlap.loc[:,['country',direction+'_'+flag_overlap]], left_on= country_group,right_on='country', how='left')\n",
    "\n",
    "    # Contibution of each layer to total exports:\n",
    "    data_for_Pc['sum_layers'] = (data_for_Pc['str_i_l']/data_for_Pc[direction+'_'+flag_overlap])**2\n",
    "    \n",
    "    sum_layers= data_for_Pc.groupby([country_group]).apply(lambda group: group.sum_layers.sum())\n",
    "\n",
    "    particip_coeff = (pd.DataFrame((L/(L-1))*(1- sum_layers),columns=['pc'+w_f+'_'+direction]).\n",
    "                      sort_values(by='pc'+w_f+'_'+direction,ascending=False))\n",
    "    return particip_coeff \n",
    "\n",
    "\n",
    "def Agregated_network (edge_data,node_info, group_class):\n",
    "    \n",
    "    # General network \n",
    "    pos_dict = node_info.loc[:,['ISO','pos','name']].set_index('ISO').to_dict(orient='index')\n",
    "    pos_dict\n",
    "\n",
    "    edge_dict =dict(zip(zip(edge_data['origin_country_ISO'], edge_data['destin_country_ISO'], edge_data[group_class]), edge_data['value']))\n",
    "    edge_dict\n",
    "\n",
    "    # Create network\n",
    "    G=nx.MultiDiGraph()\n",
    "\n",
    "    G.add_nodes_from(pos_dict)\n",
    "    nx.set_node_attributes(G,pos_dict)\n",
    "\n",
    "    G.add_edges_from(edge_dict.keys())\n",
    "    nx.set_edge_attributes(G, edge_dict, 'weight')\n",
    "    nx.set_edge_attributes(G, edge_dict.keys(), '<attribute_name>')\n",
    "    return G\n",
    "        \n",
    "\n",
    "def Make_dict_years (data_in, country_metadata, direction, group_class, year_check):\n",
    "    \"\"\" \n",
    "    Iterate everything to filter data per year, get network and network stats. \n",
    "    The output should be a the dataframe with the value of overlap and zscore for each country the year being explored. \n",
    "\n",
    "    This will be saved in a dictionary. \n",
    "    \"\"\"\n",
    "    # Load data \n",
    "    data_filt = data_in.loc[(data_in.unit =='1000 US$') & (data_in.year == year_check) & (data_in.value > 0) ,:].copy()\n",
    "\n",
    "    # Create agregated multilayer network \n",
    "    G = Agregated_network(data_filt, country_metadata, group_class = group_class)\n",
    "\n",
    "    # Degree estimations\n",
    "    out_degree= pd.DataFrame([i for i in G.out_degree()],columns=['country','out_deg']).sort_values(by='out_deg',ascending=False)\n",
    "    in_degree= pd.DataFrame([i for i in G.in_degree()],columns=['country','in_deg']).sort_values(by='in_deg',ascending=False)\n",
    "\n",
    "    # Overlap: sum of weights (out_degree)\n",
    "    overlap= pd.DataFrame([i for i in G.out_degree(weight='weight')],columns=['country','out_overl']).sort_values(by='out_overl',ascending=False)\n",
    "    in_overlap= pd.DataFrame([i for i in G.in_degree(weight='weight')],columns=['country','in_overl']).sort_values(by='in_overl',ascending=False)\n",
    "\n",
    "    overlap= pd.merge(overlap,in_overlap, on='country', copy=False)\n",
    "    overlap= pd.merge(overlap,out_degree, on='country', copy=False)\n",
    "    overlap= pd.merge(overlap,in_degree, on='country', copy=False)\n",
    "\n",
    "    # Add z score degree and overlap:\n",
    "    overlap['z_'+direction+'_deg'] = (overlap[direction+'_deg'] - overlap[direction+'_deg'].mean())/overlap[direction+'_deg'].std()\n",
    "\n",
    "    overlap['z_'+direction+'_overl'] = (overlap[direction+'_overl'] - overlap[direction+'_overl'].mean()) / overlap[direction+'_overl'].std()\n",
    "\n",
    "    # Participation coefficient: \n",
    "    partic_coeff = Participation_coeff(data_filt, overlap, direction, group_class,weight=False)\n",
    "    partic_coeff_w = Participation_coeff(data_filt, overlap, direction,group_class,weight=True)\n",
    "    partic_coeff = pd.merge(partic_coeff, partic_coeff_w, left_index=True, right_index=True,how='left')\n",
    "\n",
    "    # Merge participation and degree dataframes:\n",
    "    deg_particip = pd.merge(overlap, partic_coeff, right_index=True, left_on='country',how='left')\n",
    "    # deg_particip = pd.merge(deg_particip, partic_coeff_w, left_on='country',right_index=True,how='left',copy=False)\n",
    "    return deg_particip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_check= 2019 #'1986-1988'#2019\n",
    "direction = 'out'\n",
    "group_class = 'Food_group' # item\n",
    "#data_og = pd.read_pickle('../Data/Data_year_groups_12.pkl')\n",
    "\n",
    "country_metadata = pd.read_pickle('../Data/Country_info.pkl')\n",
    "\n",
    "data_og = pd.read_pickle('../Data/Data_food_groups.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>destin_country_ISO</th>\n",
       "      <th>origin_country_ISO</th>\n",
       "      <th>year</th>\n",
       "      <th>unit</th>\n",
       "      <th>value</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>destin_country</th>\n",
       "      <th>L1_foodex</th>\n",
       "      <th>Food_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14235148</td>\n",
       "      <td>KW</td>\n",
       "      <td>IT</td>\n",
       "      <td>1986</td>\n",
       "      <td>tonnes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>A04PE</td>\n",
       "      <td>Confectionery including chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14235170</td>\n",
       "      <td>KW</td>\n",
       "      <td>IT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1000 US$</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>A04PE</td>\n",
       "      <td>Confectionery including chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14235436</td>\n",
       "      <td>KW</td>\n",
       "      <td>SG</td>\n",
       "      <td>1986</td>\n",
       "      <td>tonnes</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>A04PE</td>\n",
       "      <td>Confectionery including chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14235456</td>\n",
       "      <td>KW</td>\n",
       "      <td>SG</td>\n",
       "      <td>1986</td>\n",
       "      <td>1000 US$</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Kuwait</td>\n",
       "      <td>A04PE</td>\n",
       "      <td>Confectionery including chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14236866</td>\n",
       "      <td>BN</td>\n",
       "      <td>CN</td>\n",
       "      <td>1986</td>\n",
       "      <td>tonnes</td>\n",
       "      <td>8.0</td>\n",
       "      <td>China, mainland</td>\n",
       "      <td>Brunei Darussalam</td>\n",
       "      <td>A04PE</td>\n",
       "      <td>Confectionery including chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846474</th>\n",
       "      <td>21929008</td>\n",
       "      <td>SZ</td>\n",
       "      <td>CH</td>\n",
       "      <td>2021</td>\n",
       "      <td>1000 US$</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Eswatini</td>\n",
       "      <td>A03DJ</td>\n",
       "      <td>Water and water-based beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846475</th>\n",
       "      <td>21929020</td>\n",
       "      <td>SZ</td>\n",
       "      <td>AT</td>\n",
       "      <td>2021</td>\n",
       "      <td>tonnes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Eswatini</td>\n",
       "      <td>A03DJ</td>\n",
       "      <td>Water and water-based beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846476</th>\n",
       "      <td>21929026</td>\n",
       "      <td>SZ</td>\n",
       "      <td>AT</td>\n",
       "      <td>2021</td>\n",
       "      <td>1000 US$</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Eswatini</td>\n",
       "      <td>A03DJ</td>\n",
       "      <td>Water and water-based beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846477</th>\n",
       "      <td>21929047</td>\n",
       "      <td>SZ</td>\n",
       "      <td>MZ</td>\n",
       "      <td>2021</td>\n",
       "      <td>tonnes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mozambique</td>\n",
       "      <td>Eswatini</td>\n",
       "      <td>A03DJ</td>\n",
       "      <td>Water and water-based beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846478</th>\n",
       "      <td>21929054</td>\n",
       "      <td>SZ</td>\n",
       "      <td>MZ</td>\n",
       "      <td>2021</td>\n",
       "      <td>1000 US$</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mozambique</td>\n",
       "      <td>Eswatini</td>\n",
       "      <td>A03DJ</td>\n",
       "      <td>Water and water-based beverages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6846479 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index destin_country_ISO origin_country_ISO  year      unit  \\\n",
       "0        14235148                 KW                 IT  1986    tonnes   \n",
       "1        14235170                 KW                 IT  1986  1000 US$   \n",
       "2        14235436                 KW                 SG  1986    tonnes   \n",
       "3        14235456                 KW                 SG  1986  1000 US$   \n",
       "4        14236866                 BN                 CN  1986    tonnes   \n",
       "...           ...                ...                ...   ...       ...   \n",
       "6846474  21929008                 SZ                 CH  2021  1000 US$   \n",
       "6846475  21929020                 SZ                 AT  2021    tonnes   \n",
       "6846476  21929026                 SZ                 AT  2021  1000 US$   \n",
       "6846477  21929047                 SZ                 MZ  2021    tonnes   \n",
       "6846478  21929054                 SZ                 MZ  2021  1000 US$   \n",
       "\n",
       "         value   origin_country     destin_country L1_foodex  \\\n",
       "0          1.0            Italy             Kuwait     A04PE   \n",
       "1         30.0            Italy             Kuwait     A04PE   \n",
       "2         17.0        Singapore             Kuwait     A04PE   \n",
       "3         27.0        Singapore             Kuwait     A04PE   \n",
       "4          8.0  China, mainland  Brunei Darussalam     A04PE   \n",
       "...        ...              ...                ...       ...   \n",
       "6846474    4.0      Switzerland           Eswatini     A03DJ   \n",
       "6846475    3.0          Austria           Eswatini     A03DJ   \n",
       "6846476    3.0          Austria           Eswatini     A03DJ   \n",
       "6846477    0.0       Mozambique           Eswatini     A03DJ   \n",
       "6846478    0.0       Mozambique           Eswatini     A03DJ   \n",
       "\n",
       "                                      Food_group  \n",
       "0              Confectionery including chocolate  \n",
       "1              Confectionery including chocolate  \n",
       "2              Confectionery including chocolate  \n",
       "3              Confectionery including chocolate  \n",
       "4              Confectionery including chocolate  \n",
       "...                                          ...  \n",
       "6846474          Water and water-based beverages  \n",
       "6846475          Water and water-based beverages  \n",
       "6846476          Water and water-based beverages  \n",
       "6846477          Water and water-based beverages  \n",
       "6846478          Water and water-based beverages  \n",
       "\n",
       "[6846479 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_og"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate estimation for all countries and years. It is saved as a dictionary with a single pandas datafarame containing all outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:35<00:00,  1.01it/s]\n",
      "100%|██████████| 36/36 [00:35<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "list_years = data_og.year.unique()\n",
    "'''\n",
    "dict_results = dict()\n",
    "for i in list_years: \n",
    "    dict_aux = Make_dict_years(data_og,i)\n",
    "    dict_results[i] = dict_aux.copy()\n",
    "'''\n",
    "dict_results_in = dict((i, Make_dict_years(data_og,country_metadata, 'in',group_class,i)) for i in tqdm(list_years))\n",
    "dict_results_out = dict((i, Make_dict_years(data_og,country_metadata, 'out',group_class,i)) for i in tqdm(list_years))\n",
    "\n",
    "#pickle.dump(dict_results, open('../Data/country_overlap_particip.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(dict_results_in[1986].pc_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>out_overl</th>\n",
       "      <th>in_overl</th>\n",
       "      <th>out_deg</th>\n",
       "      <th>in_deg</th>\n",
       "      <th>z_in_deg</th>\n",
       "      <th>z_in_overl</th>\n",
       "      <th>pc_in</th>\n",
       "      <th>pc_w_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>114432918.0</td>\n",
       "      <td>127840425.0</td>\n",
       "      <td>2655</td>\n",
       "      <td>1930</td>\n",
       "      <td>3.275163</td>\n",
       "      <td>8.037157</td>\n",
       "      <td>0.990023</td>\n",
       "      <td>0.954273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NL</td>\n",
       "      <td>75675721.0</td>\n",
       "      <td>56760949.0</td>\n",
       "      <td>2846</td>\n",
       "      <td>1692</td>\n",
       "      <td>2.698852</td>\n",
       "      <td>3.353815</td>\n",
       "      <td>0.990142</td>\n",
       "      <td>0.961331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE</td>\n",
       "      <td>68051285.0</td>\n",
       "      <td>79655080.0</td>\n",
       "      <td>2715</td>\n",
       "      <td>1696</td>\n",
       "      <td>2.708537</td>\n",
       "      <td>4.862282</td>\n",
       "      <td>0.989375</td>\n",
       "      <td>0.961579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BR</td>\n",
       "      <td>68007960.0</td>\n",
       "      <td>8169069.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>773</td>\n",
       "      <td>0.473515</td>\n",
       "      <td>0.152154</td>\n",
       "      <td>0.983771</td>\n",
       "      <td>0.938546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR</td>\n",
       "      <td>63222544.0</td>\n",
       "      <td>48049088.0</td>\n",
       "      <td>2826</td>\n",
       "      <td>1664</td>\n",
       "      <td>2.631050</td>\n",
       "      <td>2.779801</td>\n",
       "      <td>0.988145</td>\n",
       "      <td>0.965940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>HM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.398287</td>\n",
       "      <td>-0.386097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>YU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.398287</td>\n",
       "      <td>-0.386097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>SD-SS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.398287</td>\n",
       "      <td>-0.386097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>MQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.398287</td>\n",
       "      <td>-0.386097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>GS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.398287</td>\n",
       "      <td>-0.386097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    country    out_overl     in_overl  out_deg  in_deg  z_in_deg  z_in_overl  \\\n",
       "0        US  114432918.0  127840425.0     2655    1930  3.275163    8.037157   \n",
       "1        NL   75675721.0   56760949.0     2846    1692  2.698852    3.353815   \n",
       "2        DE   68051285.0   79655080.0     2715    1696  2.708537    4.862282   \n",
       "3        BR   68007960.0    8169069.0     2009     773  0.473515    0.152154   \n",
       "4        FR   63222544.0   48049088.0     2826    1664  2.631050    2.779801   \n",
       "..      ...          ...          ...      ...     ...       ...         ...   \n",
       "214      HM          0.0          0.0        0       0 -1.398287   -0.386097   \n",
       "215      YU          0.0          0.0        0       0 -1.398287   -0.386097   \n",
       "216   SD-SS          0.0          0.0        0       0 -1.398287   -0.386097   \n",
       "217      MQ          0.0          0.0        0       0 -1.398287   -0.386097   \n",
       "218      GS          0.0          0.0        0       0 -1.398287   -0.386097   \n",
       "\n",
       "        pc_in   pc_w_in  \n",
       "0    0.990023  0.954273  \n",
       "1    0.990142  0.961331  \n",
       "2    0.989375  0.961579  \n",
       "3    0.983771  0.938546  \n",
       "4    0.988145  0.965940  \n",
       "..        ...       ...  \n",
       "214       NaN       NaN  \n",
       "215       NaN       NaN  \n",
       "216       NaN       NaN  \n",
       "217       NaN       NaN  \n",
       "218       NaN       NaN  \n",
       "\n",
       "[219 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Make_dict_years(data_og,country_metadata, 'in',group_class,2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_results_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to do dynamic\n",
    "def Country_map_static (dict_results, parameters, country_list, year_list= 'All', plt_flag=True):\n",
    "    \n",
    "    if (parameters['weight'] == True):\n",
    "        w_f = '_w'\n",
    "        flag_overlap = 'overl'\n",
    "        title_overlap = 'weighted overlap'\n",
    "    else:\n",
    "        w_f = ''\n",
    "        flag_overlap = 'deg'\n",
    "        title_overlap = 'overlap (degree)'\n",
    "\n",
    "    # Define start for All flags\n",
    "    if country_list == 'All':\n",
    "        country_list = list(dict_results[list(dict_results.keys())[0]].country)\n",
    "        title_country = 'All countries'\n",
    "    else: \n",
    "        title_country  = country_list\n",
    "    \n",
    "    if year_list == 'All':\n",
    "        year_list = list(dict_results.keys())\n",
    "        title_year  = 'All years'\n",
    "\n",
    "    else: \n",
    "        title_year  = year_list[0]\n",
    "\n",
    "    # Define figure characteristics \n",
    "    if plt_flag == True :\n",
    "        maxY_plot = max([max(dict_results[y]['z_'+ direction+'_'+flag_overlap]) for y in list_years])\n",
    "        minY_plot = min([min(dict_results[y]['z_'+ direction+'_'+flag_overlap]) for y in list_years])\n",
    "\n",
    "        fig_phase, ax = plt.subplots(figsize = (6,5))\n",
    "        ax.axvline(x=1/3, color='grey', linestyle= '--', zorder =1)\n",
    "        ax.axvline(x=2/3, color='grey', linestyle= '--', zorder = 1)\n",
    "        ax.axhline(y=2, color='grey', linestyle= '--', zorder = 1)\n",
    "        ax.set_xlim (0,1)\n",
    "        ax.set_xlim (0,1)\n",
    "        ax.set_ylim((minY_plot-1,maxY_plot+1))\n",
    "\n",
    "        #\n",
    "        ax.set_ylabel('Z-score ' + title_overlap)\n",
    "        ax.set_xlabel('Participation coefficient (p)')\n",
    "        #ax.set_title ('Map with weighted overlap: '+ str(title_country) +' countries' +' & '+ str(title_year))\n",
    "        ax.set_title ('Relevance in global food trade exports: '+ str(title_country) +' & '+ str(title_year))\n",
    "\n",
    "    # Iterate for countries:\n",
    "    coords_dict = dict()\n",
    "\n",
    "    for country in country_list:\n",
    "        coords = pd.DataFrame()\n",
    "        for y in year_list:\n",
    "            to_add = dict_results[y].loc[(dict_results[y]['country']==country),('pc'+w_f+'_'+direction,'z_'+direction+'_'+flag_overlap)] \n",
    "            coords = pd.concat([coords,to_add])\n",
    "        coords.index = year_list\n",
    "\n",
    "        coords_dict[country] = coords\n",
    "        if (plt_flag ==True):\n",
    "            # Plot \n",
    "            ax.scatter(coords['pc'+w_f+'_'+direction].iloc[2:-2], coords['z_'+direction+'_'+flag_overlap].iloc[2:-2],zorder = 2,s=20,label= coords.index)\n",
    "            ax.plot(coords['pc'+w_f+'_'+direction], coords['z_'+direction+'_'+flag_overlap],zorder = 2,label= coords.index)\n",
    "            ax.scatter(coords['pc'+w_f+'_'+direction].iloc[0], coords['z_'+direction+'_'+flag_overlap].iloc[0],zorder = 2,label= coords.index[0],color = 'black')\n",
    "            ax.scatter(coords['pc'+w_f+'_'+direction].iloc[-1], coords['z_'+direction+'_'+flag_overlap].iloc[-1],zorder = 2,label= coords.index[-1],color = 'red')\n",
    "            #ax.annotate(country,(coords['pc'+w_f+'_'+direction].iloc[-1], coords['z_'+direction+'_'+flag_overlap].iloc[-1]),zorder = 2,label= coords.index[-1],color = 'steelblue')\n",
    "\n",
    "\n",
    "    fig_phase.savefig('../Plots/map_countries_export.pdf',format ='pdf',dpi=300)   \n",
    "    plt.show()\n",
    "    print(country)\n",
    "    return coords_dict\n",
    "\n",
    "\n",
    "# Coords dict \n",
    "weight =True\n",
    "group_class='Food_group'\n",
    "direction='out'\n",
    "parameters = {'group_class':group_class, 'direction': direction,'weight':weight}\n",
    "coords_dict = Country_map_static(dict_results_out,parameters, country_list='All',year_list=[2019],plt_flag = True)\n",
    "\n",
    "coords =dict_results_out[2019]\n",
    "coords.loc[(coords['pc_w_'+direction]>=2/3) & (coords['z_'+direction+'_overl']>=2),:]\n",
    "\n",
    "# pickle.dump(coords_dict, open('../Data/country_coords.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(dict_results_in[1986].pc_w_in)\n",
    "np.max(dict_results_in[1986].pc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
