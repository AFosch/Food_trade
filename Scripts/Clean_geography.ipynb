{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Clean data: Fix problems with geometries\n",
    "\n",
    "Countries are messy, need to include ISO codes and to add their position on a map (for visualisation purposes). \n",
    "\n",
    "This script pre-processes the data and gives 2 csv files as output: \n",
    "\n",
    "- ``Trade_geo.csv``: Contains the clean version of Trade_reconciled. The country names are standardised and the correct ISO2 codes are included for all countries.\n",
    "\n",
    "- ``Country_info.csv``: Contains metadata about all the countries in the dataset including their Standardised name, ISO2 code, ISO3 code (for some) and the coordinates of a representative point inside the country. *Needs to be improved to find the spatial position of the countries that have changed their name.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import networkx as nx\n",
    "import geopandas as gpd # pip installed\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# FUNCTIONS \n",
    "def ISO2_fix (match_ids):\n",
    "    # Add iso codes for all missing countries\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Canton and Enderbury Islands'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'CT'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'China, Hong Kong SAR'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'HK'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Heard and McDonald Islands'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'HM'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'China, Taiwan Province of'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'TW'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'USSR'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'SU'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Serbia and Montenegro'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'RS-ME'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Midway Island'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'UM-71'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Yugoslav SFR'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'YU'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'China, Macao SAR'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'MO'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Sudan (former)'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'SD-SS'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Johnston Island'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'UM-67'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Belgium-Luxembourg'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'BE-LU'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Czechoslovakia'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'CS'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Serbia and Montenegro'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'RS-ME'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Wake Island'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'UM-79'\n",
    "    return(match_ids)\n",
    "\n",
    "\n",
    "def Geometries_missing(shape_file):  \n",
    "    \n",
    "    #Fix Former Sudan\n",
    "    boolean_cond=(shape_file.ISO == 'SD') | (shape_file.ISO=='SS')\n",
    "    geometry_merged= shape_file.loc[boolean_cond,'geometry'].unary_union\n",
    "    sd_ss = {'ISO': 'SD-SS', 'geometry': geometry_merged}\n",
    "    \n",
    "    #Fix Serbia & Montenegro\n",
    "    boolean_cond=(shape_file.ISO == 'RS') | (shape_file.ISO=='ME')\n",
    "    geometry_merged= shape_file.loc[boolean_cond,'geometry'].unary_union\n",
    "    rs_me = {'ISO': 'RS-ME', 'geometry': geometry_merged}\n",
    "\n",
    "    #Fix Belgium & Luxembourg\n",
    "    boolean_cond=(shape_file.ISO == 'BE') | (shape_file.ISO=='LU')\n",
    "    geometry_merged= shape_file.loc[boolean_cond,'geometry'].unary_union\n",
    "    be_lu = {'ISO': 'BE-LU', 'geometry': geometry_merged}\n",
    "\n",
    "    # ADD shapefiles of other weird countries (if I find them): \n",
    "    #geometry_imported = ???\n",
    "    #taiwan = {'ISO': '??', 'geometry': geometry_imported }\n",
    "\n",
    "    # Merge data \n",
    "    to_merge = gpd.GeoDataFrame([sd_ss,rs_me,be_lu],index = ['SD-SS','RS-ME','BE-LU'])\n",
    "    shape_file2 = pd.concat([shape_file, to_merge])\n",
    "    return (shape_file2)\n",
    "\n",
    "\n",
    "def Standardise_names(data, country_match):\n",
    "    # Fix formatting isseues \n",
    "    data.loc[:,['origin_country','destin_country']]= data.loc[:,['origin_country','destin_country']].replace('Palestine','State of Palestine')\n",
    "    #data.loc[:,['origin_country','destin_country']]= data.loc[:,['origin_country','destin_country']].replace(\"Côte d'Ivoire\",\"Côte d'Ivoire\")\n",
    "    data.loc[:,['origin_country','destin_country']]= data.loc[:,['origin_country','destin_country']].replace(\"Ethiopia PDR\",'Ethiopia')\n",
    "\n",
    "    country_match.loc[:,'Country or Area']= country_match.loc[:,'Country or Area'].replace('China','China, mainland')\n",
    "    country_match.loc[:,'Country or Area']= country_match.loc[:,'Country or Area'].replace(\"Côte d’Ivoire\",\"Côte d'Ivoire\")# also change apostrophe in map dataset\n",
    "\n",
    "    all_countries = (set(data.origin_country.unique()).union(set(data.destin_country.unique()))) #find all possible countries in dataset\n",
    "    all_countries= pd.DataFrame(all_countries,columns=['Country or Area'])\n",
    "\n",
    "    no_overlap = list(set(all_countries['Country or Area']).difference(set(country_match['Country or Area'].unique())))\n",
    "    print('Countries that have changed their name:')\n",
    "    print(no_overlap)\n",
    "    return (data, country_match, all_countries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Solve country name issues \n",
    "There are many countries that are not being correctly labeled in the dataset when compared to the UN labels dataset. This dataset has the list of all the ISO2 codes of the currently existing countries. We solve the issue using the function ``Standardise_names`` for the countries where the problem is a labeling issue. \n",
    "\n",
    "However, some of the countries reported in the trade data are administrative units or countries that do not exist anymore. In this case, we will track these countries/regions using their specific ISO codes. To define it we use ``ISO2_fix``.\n",
    "\n",
    "Source: https://unstats.un.org/unsd/methodology/m49/overview/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with a label mismatch:\n",
      "['Heard and McDonald Islands', 'Czechoslovakia', 'Johnston Island', 'Midway Island', 'Wake Island', 'China, Hong Kong SAR', 'Serbia and Montenegro', 'Sudan (former)', 'China, Macao SAR', 'Yugoslav SFR', 'USSR', 'Palestine', \"Côte d'Ivoire\", 'China, Taiwan Province of', 'Belgium-Luxembourg', 'China, mainland', 'Canton and Enderbury Islands', 'Ethiopia PDR']\n",
      "Countries that have changed their name:\n",
      "['Heard and McDonald Islands', 'Czechoslovakia', 'Johnston Island', 'Midway Island', 'Wake Island', 'China, Hong Kong SAR', 'Sudan (former)', 'China, Macao SAR', 'USSR', 'Yugoslav SFR', 'China, Taiwan Province of', 'Belgium-Luxembourg', 'Serbia and Montenegro', 'Canton and Enderbury Islands']\n",
      "\n",
      "Num countries without ISO code after ISO2-fix (should be 0): 0\n"
     ]
    }
   ],
   "source": [
    "#Load data \n",
    "data_og = pd.read_csv('../Data/Trade_reconciled.csv',encoding=\"utf-8\",index_col=0).reset_index()\n",
    "data=data_og.drop(columns=['origin_country_code','destin_country_code'])\n",
    "\n",
    "# Find all countries existing across the years\n",
    "all_countries = list(set(data.origin_country.unique()).union(set(data.destin_country.unique()))) #find all possible countries in dataset 2\n",
    "\n",
    "# Load dataset with ISO codes for all countries, reported from UN stats (https://unstats.un.org/unsd/methodology/m49/overview/)\n",
    "country_match = pd.read_csv('../Data/raw_trade/UNSD — Methodology.csv',encoding=\"utf-8\",sep=';',index_col=0,keep_default_na=False).reset_index()\n",
    "\n",
    "# Find countries with label mismatch\n",
    "no_overlap = list(set(all_countries).difference(set(country_match['Country or Area'].unique())))\n",
    "print('Countries with a label mismatch:')\n",
    "print(no_overlap)\n",
    "\n",
    "# Solve possible mapping issues \n",
    "data, country_match, all_countries_std = Standardise_names(data,country_match)\n",
    "\n",
    "\n",
    "# ADD ISO ids for all countries \n",
    "match_ids= pd.merge(all_countries_std, country_match, how='left', on='Country or Area')\n",
    "\n",
    "# Add iso codes for non matching countries\n",
    "match_ids= ISO2_fix(match_ids)\n",
    "\n",
    "# Validaiton Check\n",
    "print('\\nNum countries without ISO code after ISO2-fix (should be 0): '+ str(len(match_ids.loc[match_ids['ISO-alpha2 Code'].isna(),])))\n",
    "\n",
    "# Maybe need to get iso codes form here: \n",
    "#https://data.apps.fao.org/catalog/dataset/iso-2-code-list-global-region-country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add geometries to country properties \n",
    "If we want to plot trade-network on a map we need a representative position of each country. For that we need the spatial geometry of each country. This is loaded from a shapefile. The shapefile can be linked to the data using the ISO2 codes. \n",
    "\n",
    "Of course, there are some geometries missing in our current world map. Countries have changed a lot. The countries missing should be the same for which we created artificial ISO2 codes. \n",
    "\n",
    "Source: https://hub.arcgis.com/datasets/esri::world-countries-generalized/explore?location=0.031147%2C80.508596%2C2.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_file = gpd.read_file('../Data/World_Countries_Generalized/World_Countries_Generalized.shp',keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check that the ISO codes here correspond only to the countries that were non-existing:\n",
      "['YU', 'TW', 'CT', 'CS', 'UM-71', 'UM-67', 'UM-79', 'MO', 'HK', 'SU']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ariadna/anaconda3/envs/trade/lib/python3.12/site-packages/geopandas/array.py:1459: UserWarning: CRS not set for some of the concatenation inputs. Setting output's CRS as WGS 84 (the single non-null crs provided).\n",
      "  return GeometryArray(data, crs=_get_common_crs(to_concat))\n"
     ]
    }
   ],
   "source": [
    "# ADD geometry of all countries (using ISO-2 mapping)\n",
    "shape_file = gpd.read_file('../Data/World_Countries_Generalized/World_Countries_Generalized.shp',keep_default_na=False)\n",
    "shape_file['ISO2']=shape_file.ISO #backup iso2\n",
    "shape_file_pd= shape_file.drop('geometry',axis=1) #explore\n",
    "\n",
    "shape_file= shape_file.dissolve(by='ISO2')\n",
    "shape_file= shape_file.loc[:,['ISO','geometry']]\n",
    "\n",
    "# Add missing geometries (old countries)\n",
    "shape_file = Geometries_missing(shape_file)\n",
    "#shape_file_pd= shape_file.drop('geometry',axis=1)# explore\n",
    "\n",
    "# Create representative point for each region\n",
    "rep_point=shape_file.representative_point().get_coordinates()\n",
    "\n",
    "shape_file['pos']=list(zip(rep_point.x,rep_point.y))\n",
    "\n",
    "merged_match= gpd.GeoDataFrame(pd.merge(match_ids,shape_file, how='left', left_on='ISO-alpha2 Code',right_on='ISO'))\n",
    "merged_match= (merged_match.loc[:,['Country or Area','ISO-alpha2 Code','pos']]\n",
    ".rename(columns={'Country or Area':'name','ISO-alpha2 Code':'ISO'}))\n",
    "\n",
    "# Check countries without iso code \n",
    "no_geometry = list(set(match_ids['ISO-alpha2 Code']).difference(set(shape_file['ISO'])))\n",
    "print('Check that the ISO codes here correspond only to the countries that were non-existing:')\n",
    "print(no_geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save geometries from shapefile in the dataset containing all the country info and add the ISO2 codes to the data file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add positions to dataframe with all countries: \n",
    "merged_match=gpd.GeoDataFrame(pd.merge(match_ids,shape_file, how='left',left_on='ISO-alpha2 Code',right_on='ISO'))\n",
    "merged_match= merged_match.loc[:,['Country or Area','ISO-alpha2 Code','pos']].rename(columns={'Country or Area':'name','ISO-alpha2 Code':'ISO'})\n",
    "\n",
    "# Add iso codes to data: \n",
    "data_merged = (pd.merge(merged_match, data, how='left',left_on='name',right_on='origin_country')\n",
    "            .rename(columns={'ISO': 'origin_country_ISO'}).drop(columns=['name','pos']))\n",
    "\n",
    "data_merged = (pd.merge(merged_match, data_merged,right_on='destin_country',left_on='name')\n",
    "            .rename(columns={'ISO': 'destin_country_ISO'}).drop(columns=['name','pos','index','element']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data clean: \n",
    "merged_match.to_pickle('../Data/Country_info.pkl')\n",
    "data_merged.to_pickle('../Data/Trade_geo.pkl')\n",
    "shape_file.to_pickle('../Data/Shapefile_with_positions.pkl')\n",
    "\n",
    "#merged_match.to_csv('../Data/Country_info.csv',index=False, encoding='utf-8',na_rep=\"\")\n",
    "#data_merged.to_csv('../Data/Trade_geo.csv',index=False, encoding='utf-8', na_rep=\"\")\n",
    "\n",
    "#shape_file=shape_file.drop(columns=['pos']).reset_index()\n",
    "#shape_file.to_file('../Data/Shapefile_with_positions.geojson', driver='GeoJSON') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_pickle('../Data/Data_year_groups_12.pkl')\n",
    "FAO = pd.read_csv('../FAOSTAT_data_12-11-2023.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.item.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain Code</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Item Group Code</th>\n",
       "      <th>Item Group</th>\n",
       "      <th>Item Code</th>\n",
       "      <th>Item</th>\n",
       "      <th>Factor</th>\n",
       "      <th>CPC Code</th>\n",
       "      <th>HS Code</th>\n",
       "      <th>HS07 Code</th>\n",
       "      <th>HS12 Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBH</td>\n",
       "      <td>Commodity Balances (non-food) (-2013, old meth...</td>\n",
       "      <td>2924</td>\n",
       "      <td>Alcoholic Beverages</td>\n",
       "      <td>2659</td>\n",
       "      <td>Alcohol, Non-Food</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBH</td>\n",
       "      <td>Commodity Balances (non-food) (-2013, old meth...</td>\n",
       "      <td>2913</td>\n",
       "      <td>Oilcrops</td>\n",
       "      <td>2559</td>\n",
       "      <td>Cottonseed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBH</td>\n",
       "      <td>Commodity Balances (non-food) (-2013, old meth...</td>\n",
       "      <td>2913</td>\n",
       "      <td>Oilcrops</td>\n",
       "      <td>2562</td>\n",
       "      <td>Palm kernels</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBH</td>\n",
       "      <td>Commodity Balances (non-food) (-2013, old meth...</td>\n",
       "      <td>2913</td>\n",
       "      <td>Oilcrops</td>\n",
       "      <td>2558</td>\n",
       "      <td>Rape and Mustardseed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESB</td>\n",
       "      <td>Cropland Nutrient Budget</td>\n",
       "      <td>5081</td>\n",
       "      <td>Nutrient Budget</td>\n",
       "      <td>5082</td>\n",
       "      <td>Leaching</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11160</th>\n",
       "      <td>QV</td>\n",
       "      <td>Value of Agricultural Production</td>\n",
       "      <td>1735</td>\n",
       "      <td>Vegetables Primary</td>\n",
       "      <td>417</td>\n",
       "      <td>Peas, green</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>070810</td>\n",
       "      <td>070810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11161</th>\n",
       "      <td>QV</td>\n",
       "      <td>Value of Agricultural Production</td>\n",
       "      <td>1735</td>\n",
       "      <td>Vegetables Primary</td>\n",
       "      <td>394</td>\n",
       "      <td>Pumpkins, squash and gourds</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>070990</td>\n",
       "      <td>070993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11162</th>\n",
       "      <td>QV</td>\n",
       "      <td>Value of Agricultural Production</td>\n",
       "      <td>1735</td>\n",
       "      <td>Vegetables Primary</td>\n",
       "      <td>373</td>\n",
       "      <td>Spinach</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>070970</td>\n",
       "      <td>070970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11163</th>\n",
       "      <td>QV</td>\n",
       "      <td>Value of Agricultural Production</td>\n",
       "      <td>1735</td>\n",
       "      <td>Vegetables Primary</td>\n",
       "      <td>423</td>\n",
       "      <td>String beans</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01241.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>070820</td>\n",
       "      <td>070820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11164</th>\n",
       "      <td>QV</td>\n",
       "      <td>Value of Agricultural Production</td>\n",
       "      <td>1735</td>\n",
       "      <td>Vegetables Primary</td>\n",
       "      <td>388</td>\n",
       "      <td>Tomatoes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>01234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>070200</td>\n",
       "      <td>070200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11165 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Domain Code                                             Domain  \\\n",
       "0             CBH  Commodity Balances (non-food) (-2013, old meth...   \n",
       "1             CBH  Commodity Balances (non-food) (-2013, old meth...   \n",
       "2             CBH  Commodity Balances (non-food) (-2013, old meth...   \n",
       "3             CBH  Commodity Balances (non-food) (-2013, old meth...   \n",
       "4             ESB                           Cropland Nutrient Budget   \n",
       "...           ...                                                ...   \n",
       "11160          QV                   Value of Agricultural Production   \n",
       "11161          QV                   Value of Agricultural Production   \n",
       "11162          QV                   Value of Agricultural Production   \n",
       "11163          QV                   Value of Agricultural Production   \n",
       "11164          QV                   Value of Agricultural Production   \n",
       "\n",
       "      Item Group Code           Item Group Item Code  \\\n",
       "0                2924  Alcoholic Beverages      2659   \n",
       "1                2913             Oilcrops      2559   \n",
       "2                2913             Oilcrops      2562   \n",
       "3                2913             Oilcrops      2558   \n",
       "4                5081      Nutrient Budget      5082   \n",
       "...               ...                  ...       ...   \n",
       "11160            1735   Vegetables Primary       417   \n",
       "11161            1735   Vegetables Primary       394   \n",
       "11162            1735   Vegetables Primary       373   \n",
       "11163            1735   Vegetables Primary       423   \n",
       "11164            1735   Vegetables Primary       388   \n",
       "\n",
       "                              Item  Factor  CPC Code  HS Code HS07 Code  \\\n",
       "0                Alcohol, Non-Food     1.0       NaN      NaN       NaN   \n",
       "1                       Cottonseed     1.0       NaN      NaN       NaN   \n",
       "2                     Palm kernels     1.0       NaN      NaN       NaN   \n",
       "3             Rape and Mustardseed     1.0       NaN      NaN       NaN   \n",
       "4                         Leaching     1.0       NaN      NaN       NaN   \n",
       "...                            ...     ...       ...      ...       ...   \n",
       "11160                  Peas, green     1.0     01242      NaN    070810   \n",
       "11161  Pumpkins, squash and gourds     1.0     01235      NaN    070990   \n",
       "11162                      Spinach     1.0     01215      NaN    070970   \n",
       "11163                 String beans     1.0  01241.01      NaN    070820   \n",
       "11164                     Tomatoes     1.0     01234      NaN    070200   \n",
       "\n",
       "      HS12 Code  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "...         ...  \n",
       "11160    070810  \n",
       "11161    070993  \n",
       "11162    070970  \n",
       "11163    070820  \n",
       "11164    070200  \n",
       "\n",
       "[11165 rows x 11 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered= FAO.loc[FAO.Item.isin(data.item.unique()),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Commodity Balances (non-food) (-2013, old methodology)',\n",
       "       'Crops and livestock products', 'Emissions from Crops',\n",
       "       'Emissions from Livestock', 'Food Balances (2010-)',\n",
       "       'Food Balances (-2013, old methodology and population)',\n",
       "       'Livestock Manure', 'Livestock Patterns', 'Producer Prices',\n",
       "       'Producer Prices (old series)', 'Production Indices',\n",
       "       'Supply Utilization Accounts (2010-)', 'Trade Indices',\n",
       "       'Value of Agricultural Production'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered['Domain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FoodEx database: https://efsa.onlinelibrary.wiley.com/doi/epdf/10.2903/sp.efsa.2015.EN-804 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
