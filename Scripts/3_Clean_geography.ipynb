{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Clean data: Fix problems with geometries\n",
    "\n",
    "Countries are messy, need to include ISO codes and to add their position on a map (for visualisation purposes). \n",
    "\n",
    "This script pre-processes the data and gives 2 csv files as output: \n",
    "\n",
    "- ``Trade_geo.csv``: Contains the clean version of Trade_reconciled. The country names are standardised and the correct ISO2 codes are included for all countries.\n",
    "\n",
    "- ``Country_info.csv``: Contains metadata about all the countries in the dataset including their Standardised name, ISO2 code, ISO3 code (for some) and the coordinates of a representative point inside the country. *Needs to be improved to find the spatial position of the countries that have changed their name.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import networkx as nx\n",
    "import geopandas as gpd # pip installed\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# FUNCTIONS \n",
    "def ISO2_fix (match_ids):\n",
    "    # Add iso codes for all missing countries\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Canton and Enderbury Islands'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'CT'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'China, Hong Kong SAR'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'HK'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Heard and McDonald Islands'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'HM'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'China, Taiwan Province of'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'TW'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'USSR'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'SU'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Serbia and Montenegro'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'RS-ME'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Midway Island'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'UM-71'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Yugoslav SFR'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'YU'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'China, Macao SAR'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'MO'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Sudan (former)'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'SD-SS'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Johnston Island'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'UM-67'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Belgium-Luxembourg'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'BE-LU'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Czechoslovakia'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'CS'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Serbia and Montenegro'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'RS-ME'\n",
    "\n",
    "    bool_cond= match_ids.loc[:,'Country or Area']== 'Wake Island'\n",
    "    match_ids.loc[bool_cond,'ISO-alpha2 Code']= 'UM-79'\n",
    "    return(match_ids)\n",
    "\n",
    "\n",
    "def Geometries_missing(shape_file):  \n",
    "    '''Function to handle missing or incorrectly defined geometries for specific countries \n",
    "    in a shapefile.\n",
    "\n",
    "    Parameters:\n",
    "    - shape_file (geopandas.GeoDataFrame): Input shapefile containing geometries \n",
    "      and associated country ISO codes.\n",
    "\n",
    "    Returns:\n",
    "    - geopandas.GeoDataFrame: Updated shapefile with corrected geometries for specific countries.\n",
    "    '''\n",
    "\n",
    "    #Fix Former Sudan\n",
    "    boolean_cond=(shape_file.ISO == 'SD') | (shape_file.ISO=='SS')\n",
    "    geometry_merged= shape_file.loc[boolean_cond,'geometry'].unary_union\n",
    "    sd_ss = {'ISO': 'SD-SS', 'geometry': geometry_merged}\n",
    "    \n",
    "    #Fix Serbia & Montenegro\n",
    "    boolean_cond=(shape_file.ISO == 'RS') | (shape_file.ISO=='ME')\n",
    "    geometry_merged= shape_file.loc[boolean_cond,'geometry'].unary_union\n",
    "    rs_me = {'ISO': 'RS-ME', 'geometry': geometry_merged}\n",
    "\n",
    "    #Fix Belgium & Luxembourg\n",
    "    boolean_cond=(shape_file.ISO == 'BE') | (shape_file.ISO=='LU')\n",
    "    geometry_merged= shape_file.loc[boolean_cond,'geometry'].unary_union\n",
    "    be_lu = {'ISO': 'BE-LU', 'geometry': geometry_merged}\n",
    "\n",
    "    # ADD shapefiles of other weird countries (if I find them): \n",
    "    #geometry_imported = ???\n",
    "    #taiwan = {'ISO': '??', 'geometry': geometry_imported }\n",
    "\n",
    "    # Merge data \n",
    "    to_merge = gpd.GeoDataFrame([sd_ss,rs_me,be_lu],index = ['SD-SS','RS-ME','BE-LU'])\n",
    "    shape_file2 = pd.concat([shape_file, to_merge])\n",
    "    return (shape_file2)\n",
    "\n",
    "\n",
    "def Standardise_names(data, country_match):\n",
    "    # Fix formatting isseues \n",
    "    data.loc[:,['origin_country','destin_country']]= data.loc[:,['origin_country','destin_country']].replace('Palestine','State of Palestine')\n",
    "    #data.loc[:,['origin_country','destin_country']]= data.loc[:,['origin_country','destin_country']].replace(\"Côte d'Ivoire\",\"Côte d'Ivoire\")\n",
    "    data.loc[:,['origin_country','destin_country']]= data.loc[:,['origin_country','destin_country']].replace(\"Ethiopia PDR\",'Ethiopia')\n",
    "\n",
    "    country_match.loc[:,'Country or Area']= country_match.loc[:,'Country or Area'].replace('China','China, mainland')\n",
    "    country_match.loc[:,'Country or Area']= country_match.loc[:,'Country or Area'].replace(\"Côte d’Ivoire\",\"Côte d'Ivoire\")# also change apostrophe in map dataset\n",
    "\n",
    "    all_countries = (set(data.origin_country.unique()).union(set(data.destin_country.unique()))) #find all possible countries in dataset\n",
    "    all_countries= pd.DataFrame(all_countries,columns=['Country or Area'])\n",
    "\n",
    "    no_overlap = list(set(all_countries['Country or Area']).difference(set(country_match['Country or Area'].unique())))\n",
    "    print('Countries that have changed their name:')\n",
    "    print(no_overlap)\n",
    "    return (data, country_match, all_countries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Solve country name issues \n",
    "There are many countries that are not being correctly labeled in the dataset when compared to the UN labels dataset. This dataset has the list of all the ISO2 codes of the currently existing countries. We solve the issue using the function ``Standardise_names`` for the countries where the problem is a labeling issue. \n",
    "\n",
    "However, some of the countries reported in the trade data are administrative units or countries that do not exist anymore. In this case, we will track these countries/regions using their specific ISO codes. To define it we use ``ISO2_fix``.\n",
    "\n",
    "Source: https://unstats.un.org/unsd/methodology/m49/overview/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n",
      "Countries with a label mismatch:\n",
      "['Heard and McDonald Islands', 'USSR', 'Czechoslovakia', 'Palestine', \"Côte d'Ivoire\", 'Wake Island', 'Ethiopia PDR', 'Serbia and Montenegro', 'China, mainland', 'Johnston Island', 'Belgium-Luxembourg', 'China, Hong Kong SAR', 'China, Macao SAR', 'Yugoslav SFR', 'China, Taiwan Province of', 'Sudan (former)', 'Canton and Enderbury Islands', 'Midway Island']\n",
      "Countries that have changed their name:\n",
      "['Heard and McDonald Islands', 'USSR', 'Czechoslovakia', 'Wake Island', 'Serbia and Montenegro', 'Johnston Island', 'Belgium-Luxembourg', 'China, Hong Kong SAR', 'China, Macao SAR', 'Yugoslav SFR', 'China, Taiwan Province of', 'Sudan (former)', 'Canton and Enderbury Islands', 'Midway Island']\n",
      "\n",
      "Num countries without ISO code after ISO2-fix (should be 0): 0\n"
     ]
    }
   ],
   "source": [
    "#Load data \n",
    "data_og = pd.read_csv('../Data/Trade_reconciled.csv',encoding=\"utf-8\",index_col=0).reset_index()\n",
    "data=data_og.drop(columns=['origin_country_code','destin_country_code'])\n",
    "\n",
    "# Find all countries existing across the years\n",
    "all_countries = list(set(data.origin_country.unique()).union(set(data.destin_country.unique()))) #find all possible countries in dataset 2\n",
    "print(len(all_countries))\n",
    "# Load dataset with ISO codes for all countries, reported from UN stats (https://unstats.un.org/unsd/methodology/m49/overview/)\n",
    "country_match = pd.read_csv('../Data/raw_trade/UNSD — Methodology.csv',encoding=\"utf-8\",sep=';',index_col=0,keep_default_na=False).reset_index()\n",
    "\n",
    "# Find countries with label mismatch\n",
    "no_overlap = list(set(all_countries).difference(set(country_match['Country or Area'].unique())))\n",
    "print('Countries with a label mismatch:')\n",
    "print(no_overlap)\n",
    "\n",
    "# Solve possible mapping issues \n",
    "data, country_match, all_countries_std = Standardise_names(data,country_match)\n",
    "\n",
    "# ADD ISO ids for all countries \n",
    "match_ids= pd.merge(all_countries_std, country_match, how='left', on='Country or Area')\n",
    "\n",
    "# Add iso codes for non matching countries\n",
    "match_ids= ISO2_fix(match_ids)\n",
    "\n",
    "# Validaiton Check\n",
    "print('\\nNum countries without ISO code after ISO2-fix (should be 0): '+ str(len(match_ids.loc[match_ids['ISO-alpha2 Code'].isna(),])))\n",
    "\n",
    "# Maybe need to get iso codes form here: \n",
    "#https://data.apps.fao.org/catalog/dataset/iso-2-code-list-global-region-country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add geometries to country properties \n",
    "If we want to plot trade-network on a map we need a representative position of each country. For that we need the spatial geometry of each country. This is loaded from a shapefile. The shapefile can be linked to the data using the ISO2 codes. \n",
    "\n",
    "Of course, there are some geometries missing in our current world map. Countries have changed a lot. The countries missing should be the same for which we created artificial ISO2 codes. \n",
    "\n",
    "Source: https://hub.arcgis.com/datasets/esri::world-countries-generalized/explore?location=0.031147%2C80.508596%2C2.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_file = gpd.read_file('../Data/World_Countries_Generalized/World_Countries_Generalized.shp',keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check that the ISO codes here correspond only to the countries that were non-existing:\n",
      "['SU', 'HK', 'TW', 'UM-79', 'UM-67', 'YU', 'CT', 'MO', 'CS', 'UM-71']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ariadna/anaconda3/envs/trade/lib/python3.12/site-packages/geopandas/array.py:1459: UserWarning: CRS not set for some of the concatenation inputs. Setting output's CRS as WGS 84 (the single non-null crs provided).\n",
      "  return GeometryArray(data, crs=_get_common_crs(to_concat))\n"
     ]
    }
   ],
   "source": [
    "# ADD geometry of all countries (using ISO-2 mapping)\n",
    "shape_file = gpd.read_file('../Data/World_Countries_Generalized/World_Countries_Generalized.shp',keep_default_na=False)\n",
    "shape_file['ISO2']=shape_file.ISO #backup iso2\n",
    "shape_file_pd= shape_file.drop('geometry',axis=1) #explore\n",
    "\n",
    "shape_file= shape_file.dissolve(by='ISO2')\n",
    "shape_file= shape_file.loc[:,['ISO','geometry']]\n",
    "\n",
    "# Add missing geometries (old countries)\n",
    "shape_file = Geometries_missing(shape_file)\n",
    "#shape_file_pd= shape_file.drop('geometry',axis=1)# explore\n",
    "\n",
    "# Create representative point for each region\n",
    "rep_point=shape_file.representative_point().get_coordinates()\n",
    "\n",
    "shape_file['pos']=list(zip(rep_point.x,rep_point.y))\n",
    "\n",
    "merged_match= gpd.GeoDataFrame(pd.merge(match_ids,shape_file, how='left', left_on='ISO-alpha2 Code',right_on='ISO'))\n",
    "merged_match= (merged_match.loc[:,['Country or Area','ISO-alpha2 Code','pos']]\n",
    ".rename(columns={'Country or Area':'name','ISO-alpha2 Code':'ISO'}))\n",
    "\n",
    "# Check countries without iso code \n",
    "no_geometry = list(set(match_ids['ISO-alpha2 Code']).difference(set(shape_file['ISO'])))\n",
    "print('Check that the ISO codes here correspond only to the countries that were non-existing:')\n",
    "print(no_geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save geometries from shapefile in the dataset containing all the country info and add the ISO2 codes to the data file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add positions to dataframe with all countries: \n",
    "merged_match=gpd.GeoDataFrame(pd.merge(match_ids,shape_file, how='left',left_on='ISO-alpha2 Code',right_on='ISO'))\n",
    "merged_match= merged_match.loc[:,['Country or Area','ISO-alpha2 Code','pos']].rename(columns={'Country or Area':'name','ISO-alpha2 Code':'ISO'})\n",
    "\n",
    "# Add iso codes to data: \n",
    "data_merged = (pd.merge(merged_match, data, how='left',left_on='name',right_on='origin_country')\n",
    "            .rename(columns={'ISO': 'origin_country_ISO'}).drop(columns=['name','pos']))\n",
    "\n",
    "data_merged = (pd.merge(merged_match, data_merged,right_on='destin_country',left_on='name')\n",
    "            .rename(columns={'ISO': 'destin_country_ISO'}).drop(columns=['name','pos','index','element']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data clean: \n",
    "merged_match.to_pickle('../Data/Country_info.pkl')\n",
    "data_merged.to_pickle('../Data/Trade_geo.pkl')\n",
    "shape_file.to_pickle('../Data/Shapefile_with_positions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FoodEx database: https://efsa.onlinelibrary.wiley.com/doi/epdf/10.2903/sp.efsa.2015.EN-804 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
