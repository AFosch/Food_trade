{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create multliayer Food groups \n",
    "It is a copy of Multilayer food_groups.ipynb but that I am going to mess-up to tranform into a code that I can apply to make trajectories of a country across the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import networkx as nx\n",
    "import geopandas as gpd # pip installed\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION DEFINITION:\n",
    "def Food_group_sum (data, f_group):\n",
    "    filt_data= data.loc[data.Food_group == f_group,:]\n",
    "    data_grouped= filt_data.groupby(['Food_group','unit','origin_country','destin_country','year'])\n",
    "    filt_data.loc[:,'value']= data_grouped.value.transform('sum')\n",
    "\n",
    "    filt_data.loc[:,'item']= f_group\n",
    "    return(filt_data)\n",
    "\n",
    "def FoodEx_aggregation (data):\n",
    "    food_groups = data.Food_group.unique() \n",
    "\n",
    "    # Iterate per food group\n",
    "    data_fg= Food_group_sum(data,food_groups[0])\n",
    "    \n",
    "    for f in tqdm(food_groups[1:]): \n",
    "        data_fg= pd.concat([data_fg, Food_group_sum(data,f)], ignore_index=True)\n",
    "\n",
    "    data_out = data_fg.drop_duplicates()\n",
    "    return data_out.drop(columns='item')\n",
    "\n",
    "def Node_strength(data, direction, group_class, weight = True):\n",
    "    \"\"\" Calculate the node relevance in each layer of the multilayer network. \n",
    "    In a weighted directed network the country strenght is the sum of the magnitude exported by that country in that layer.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): Input DataFrame containing trade data for a single year. The dataframe must contain \n",
    "    the columns: 'item', 'unit', 'origin_country_ISO', and 'value'.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with country strength for each combination of 'item' and 'unit', sorted from highest to lowest. \n",
    "    Columns include 'item', 'unit', 'origin_country_ISO', and the calculated 'value' for node strength.\n",
    "\n",
    "    Example:\n",
    "    >>> df_result = Node_strength_w(input_data)\n",
    "    \"\"\"\n",
    "\n",
    "    if direction == 'out':\n",
    "        country_group = 'origin_country_ISO'\n",
    "    else: \n",
    "        country_group = 'destin_country_ISO'\n",
    "\n",
    "    if (weight==True):\n",
    "        str_i_l = data.groupby([group_class,'unit']).apply(lambda group: group.loc[:,[country_group,'value']].\n",
    "                                                        pivot_table(index=country_group, aggfunc='sum').\n",
    "                                                        sort_values(by = 'value',ascending=False))\n",
    "        strength_i_l= str_i_l.reset_index(level=[group_class,'unit',country_group]).rename(columns={'value':'str_i_l'})\n",
    "\n",
    "    else:\n",
    "        data['dum_weight']= 1\n",
    "        str_i_l = data.groupby([group_class,'unit']).apply(lambda group: group.loc[:,[country_group,'value']].\n",
    "                                                        pivot_table(index=country_group, aggfunc=lambda x: len(x)).\n",
    "                                                        sort_values(by = 'value',ascending=False))\n",
    "        strength_i_l= str_i_l.reset_index(level=[group_class,'unit',country_group]).rename(columns={'value':'str_i_l'})\n",
    "\n",
    "    return strength_i_l\n",
    "\n",
    "def Participation_coeff (data, overlap, direction, group_class, weight):\n",
    "\n",
    "    if (weight == True):\n",
    "        w_f = '_w'\n",
    "        flag_overlap = 'overl'\n",
    "    else:\n",
    "        w_f = ''\n",
    "        flag_overlap = 'deg'\n",
    "\n",
    "    if direction == 'out':\n",
    "        country_group = 'origin_country_ISO'\n",
    "    else: \n",
    "        country_group = 'destin_country_ISO'\n",
    "    #Define elements for part_coeff\n",
    "    L = len(data[group_class].unique()) # Is this correct???\n",
    "    \n",
    "    s_i_l = Node_strength(data, direction, group_class,weight)\n",
    "\n",
    "    # Prepare data\n",
    "    #data_for_Pc = pd.merge(s_i_l, o_i, left_on= 'origin_country_ISO',right_index=True, how='left')\n",
    "    data_for_Pc = pd.merge(s_i_l, overlap.loc[:,['country',direction+'_'+flag_overlap]], left_on= country_group,right_on='country', how='left')\n",
    "\n",
    "    # Contibution of each layer to total exports:\n",
    "    data_for_Pc['sum_layers'] = (data_for_Pc['str_i_l']/data_for_Pc[direction+'_'+flag_overlap])**2\n",
    "    \n",
    "    sum_layers= data_for_Pc.groupby([country_group]).apply(lambda group: group.sum_layers.sum())\n",
    "\n",
    "    particip_coeff = (pd.DataFrame((L/(L-1))*(1- sum_layers),columns=['pc'+w_f+'_'+direction]).\n",
    "                      sort_values(by='pc'+w_f+'_'+direction,ascending=False))\n",
    "    return particip_coeff \n",
    "\n",
    "def Agregated_network (edge_data,node_info, group_class):\n",
    "    \n",
    "    # General network \n",
    "    pos_dict = node_info.loc[:,['ISO','pos','name']].set_index('ISO').to_dict(orient='index')\n",
    "    pos_dict\n",
    "\n",
    "    edge_dict =dict(zip(zip(edge_data['origin_country_ISO'], edge_data['destin_country_ISO'], edge_data[group_class]), edge_data['value']))\n",
    "    edge_dict\n",
    "\n",
    "    # Create network\n",
    "    G=nx.MultiDiGraph()\n",
    "\n",
    "    G.add_nodes_from(pos_dict)\n",
    "    nx.set_node_attributes(G,pos_dict)\n",
    "\n",
    "    G.add_edges_from(edge_dict.keys())\n",
    "    nx.set_edge_attributes(G, edge_dict, 'weight')\n",
    "    nx.set_edge_attributes(G, edge_dict.keys(), '<attribute_name>')\n",
    "    return G\n",
    "        \n",
    "def Make_dict_years (data_in, country_metadata, direction, group_class, year_check):\n",
    "    \"\"\" \n",
    "    Iterate everything to filter data per year, get network and network stats. \n",
    "    The output should be a the dataframe with the value of overlap and zscore for each country the year being explored. \n",
    "\n",
    "    This will be saved in a dictionary. \n",
    "    \"\"\"\n",
    "\n",
    "    # Load data \n",
    "    data_filt = data_in.loc[(data_in.unit =='1000 US$') & (data_in.year == year_check) & (data_in.value > 0) ,:].copy()\n",
    "\n",
    "    # Create agregated multilayer network \n",
    "    G = Agregated_network(data_filt, country_metadata, group_class = group_class)\n",
    "\n",
    "    # Degree estimations\n",
    "    out_degree= pd.DataFrame([i for i in G.out_degree()],columns=['country','out_deg']).sort_values(by='out_deg',ascending=False)\n",
    "    in_degree= pd.DataFrame([i for i in G.in_degree()],columns=['country','in_deg']).sort_values(by='in_deg',ascending=False)\n",
    "\n",
    "    # Overlap: sum of weights (out_degree)\n",
    "    overlap= pd.DataFrame([i for i in G.out_degree(weight='weight')],columns=['country','out_overl']).sort_values(by='out_overl',ascending=False)\n",
    "    in_overlap= pd.DataFrame([i for i in G.in_degree(weight='weight')],columns=['country','in_overl']).sort_values(by='in_overl',ascending=False)\n",
    "\n",
    "    overlap= pd.merge(overlap,in_overlap, on='country', copy=False)\n",
    "    overlap= pd.merge(overlap,out_degree, on='country', copy=False)\n",
    "    overlap= pd.merge(overlap,in_degree, on='country', copy=False)\n",
    "\n",
    "    # Add z score degree and overlap:\n",
    "    overlap['z_'+direction+'_deg'] = (overlap[direction+'_deg'] - overlap[direction+'_deg'].mean())/overlap[direction+'_deg'].std()\n",
    "\n",
    "    overlap['z_'+direction+'_overl'] = (overlap[direction+'_overl'] - overlap[direction+'_overl'].mean()) / overlap[direction+'_overl'].std()\n",
    "\n",
    "    # Participation coefficient: \n",
    "    partic_coeff = Participation_coeff(data_filt, overlap, direction, group_class,weight=False)\n",
    "    partic_coeff_w = Participation_coeff(data_filt, overlap, direction,group_class,weight=True)\n",
    "    partic_coeff = pd.merge(partic_coeff, partic_coeff_w, left_index=True, right_index=True,how='left')\n",
    "\n",
    "    # Merge participation and degree dataframes:\n",
    "    deg_particip = pd.merge(overlap, partic_coeff, right_index=True, left_on='country',how='left')\n",
    "    return deg_particip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_check= 2019 #'1986-1988'#2019\n",
    "direction = 'out'\n",
    "group_class = 'Food_group' # item\n",
    "#data_og = pd.read_pickle('../Data/Data_year_groups_12.pkl')\n",
    "\n",
    "country_metadata = pd.read_pickle('../Data/Country_info.pkl')\n",
    "\n",
    "data_og = pd.read_pickle('../Data/Data_food_groups.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregate data in the selected group_class:\n",
    "if group_class == 'Food_group':\n",
    "    data_og = FoodEx_aggregation(data_og)\n",
    "    data_og = data_og.sort_values(by=['Food_group','year']).reset_index()\n",
    "else:\n",
    "    data_og['Food_group'] = data_og['item'] #need to fix\n",
    "data_og"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate estimation for all countries and years. It is saved as a dictionary with a single pandas datafarame containing all outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_years = data_og.year.unique()\n",
    "\n",
    "dict_results_in = dict((i, Make_dict_years(data_og,country_metadata, 'in', group_class,i)) for i in tqdm(list_years))\n",
    "dict_results_out = dict((i, Make_dict_years(data_og,country_metadata, 'out', group_class,i)) for i in tqdm(list_years))\n",
    "\n",
    "#pickle.dump(dict_results, open('../Data/country_overlap_particip.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(dict_results_in[1986].pc_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to do dynamic\n",
    "def Country_map_static (dict_results, parameters, country_list, year_list= 'All', plt_flag=True):\n",
    "    \n",
    "    if (parameters['weight'] == True):\n",
    "        w_f = '_w'\n",
    "        flag_overlap = 'overl'\n",
    "        title_overlap = 'weighted overlap'\n",
    "    else:\n",
    "        w_f = ''\n",
    "        flag_overlap = 'deg'\n",
    "        title_overlap = 'overlap (degree)'\n",
    "\n",
    "    # Define start for All flags\n",
    "    if country_list == 'All':\n",
    "        country_list = list(dict_results[list(dict_results.keys())[0]].country)\n",
    "        title_country = 'All countries'\n",
    "    else: \n",
    "        title_country  = country_list\n",
    "    \n",
    "    if year_list == 'All':\n",
    "        year_list = list(dict_results.keys())\n",
    "        title_year  = 'All years'\n",
    "    else: \n",
    "        title_year  = year_list[0]\n",
    "\n",
    "    if direction == 'in':\n",
    "        dir_title = 'imports'\n",
    "    else: \n",
    "        dir_title = 'exports'\n",
    "\n",
    "    # Define figure characteristics \n",
    "    if plt_flag == True :\n",
    "        maxY_plot = max([max(dict_results[y]['z_'+ direction+'_'+flag_overlap]) for y in list_years])\n",
    "        minY_plot = min([min(dict_results[y]['z_'+ direction+'_'+flag_overlap]) for y in list_years])\n",
    "\n",
    "        fig_phase, ax = plt.subplots(figsize = (6,5))\n",
    "        ax.axvline(x=1/3, color='grey', linestyle= '--', zorder =1)\n",
    "        ax.axvline(x=2/3, color='grey', linestyle= '--', zorder = 1)\n",
    "        ax.axhline(y=2, color='grey', linestyle= '--', zorder = 1)\n",
    "        ax.set_xlim (0,1)\n",
    "        ax.set_xlim (0,1)\n",
    "        ax.set_ylim((minY_plot-1,maxY_plot+1))\n",
    "\n",
    "        #\n",
    "        ax.set_ylabel('Z-score ' + title_overlap)\n",
    "        ax.set_xlabel('Participation coefficient (p)')\n",
    "        #ax.set_title ('Map with weighted overlap: '+ str(title_country) +' countries' +' & '+ str(title_year))\n",
    "        ax.set_title ('Relevance in global food trade '+dir_title +': '+ str(title_country) +' & '+ str(title_year))\n",
    "\n",
    "    # Iterate for countries:\n",
    "    coords_dict = dict()\n",
    "\n",
    "    for country in country_list:\n",
    "        coords = pd.DataFrame()\n",
    "        for y in year_list:\n",
    "            to_add = dict_results[y].loc[(dict_results[y]['country']==country),('pc'+w_f+'_'+direction,'z_'+direction+'_'+flag_overlap)] \n",
    "            coords = pd.concat([coords,to_add])\n",
    "        coords.index = year_list\n",
    "\n",
    "        coords_dict[country] = coords\n",
    "        if (plt_flag ==True):\n",
    "            # Plot \n",
    "            ax.scatter(coords['pc'+w_f+'_'+direction].iloc[2:-2], coords['z_'+direction+'_'+flag_overlap].iloc[2:-2],zorder = 2,s=20,label= coords.index)\n",
    "            ax.plot(coords['pc'+w_f+'_'+direction], coords['z_'+direction+'_'+flag_overlap],zorder = 2,label= coords.index)\n",
    "            ax.scatter(coords['pc'+w_f+'_'+direction].iloc[0], coords['z_'+direction+'_'+flag_overlap].iloc[0],zorder = 2,label= coords.index[0],color = 'black')\n",
    "            ax.scatter(coords['pc'+w_f+'_'+direction].iloc[-1], coords['z_'+direction+'_'+flag_overlap].iloc[-1],zorder = 2,label= coords.index[-1],color = 'red')\n",
    "            ax.annotate(country,(coords['pc'+w_f+'_'+direction].iloc[-1], coords['z_'+direction+'_'+flag_overlap].iloc[-1]),zorder = 2,label= coords.index[-1],color = 'steelblue')\n",
    "\n",
    "    fig_phase.savefig('../Plots/map_countries_export.pdf',format ='pdf',dpi=300)   \n",
    "    plt.show()\n",
    "    print(country)\n",
    "    return coords_dict\n",
    "\n",
    "\n",
    "# Coords dict \n",
    "weight =True\n",
    "group_class = 'Food_group'\n",
    "direction = 'out'\n",
    "parameters = {'group_class':group_class, 'direction': direction,'weight':weight}\n",
    "coords_dict = Country_map_static(dict_results_out,parameters, country_list='All',year_list=[2000],plt_flag = True)\n",
    "\n",
    "coords =dict_results_out[201]\n",
    "coords.loc[(coords['pc_w_'+direction]>=2/3) & (coords['z_'+direction+'_overl']>=2),:]\n",
    "\n",
    "# pickle.dump(coords_dict, open('../Data/country_coords.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(dict_results_in[1986].pc_w_in)\n",
    "np.max(dict_results_in[1986].pc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
